# Training and sampling configuration for a char-level Transformer model.
# Notes on interplay:
# - Effective batch (in tokens) per optimizer update = batch_size * grad_accum_steps * block_size.
# - Memory roughly scales with n_layer * n_head and quadratically with block_size, and linearly with batch_size.
# - [train.data].block_size must be <= [train.model].block_size (model context capacity).
# - If [train.schedule].decay_lr = false, warmup/decay/min_lr are ignored.
# - Checkpoint selection uses ckpt_metric with optional smoothing and EMA if configured.

[train.model]
# mid-size model tuned for Apple Silicon (M2 Pro) with fp16 on MPS

# Number of Transformer layers (blocks); increases capacity and compute/memory cost.
n_layer = 8
# Number of attention heads per layer; must divide n_embd; more heads can help stability at added cost.
n_head = 8
# Embedding/hidden size; larger increases model capacity and compute.
n_embd = 512
# Maximum context length the model is built for (positional embeddings); must be >= [train.data].block_size.
# Increasing this raises memory/time roughly ~ O(block_size^2) per layer due to attention.
block_size = 256
# Dropout rate for regularization during training; set >0 to regularize, 0.0 for deterministic/fast runs.
dropout = 0.1
# Whether to include bias terms in linear/LayerNorm layers; false is common for GPT-style models.
bias = false

[train.data]
# Folder containing the preprocessed dataset files referenced below.
dataset_dir = "./datasets"
# Training data file name (relative to dataset_dir).
train_bin = "train.bin"
# Validation data file name (relative to dataset_dir).
val_bin = "val.bin"
# Metadata (e.g., vocab/encoding) file name (relative to dataset_dir).
meta_pkl = "meta.pkl"
# Character-level n-gram size used during dataset preparation (1 = single/chars, 3 = trigrams, etc.)
ngram_size = 3
# Micro-batch size per optimization step (per device); tuned for MPS memory
batch_size = 20
# Sequence length; ensure <= [train.model].block_size
block_size = 256
# Number of gradient accumulation steps to increase effective batch without extra memory
grad_accum_steps = 1
# Sampling policy: deterministic sequential coverage for char dataset
sampler = "sequential"

[train.optim]
# Base learning rate used by the optimizer; interacts with schedule below if decay_lr = true.
learning_rate = 0.0003
# L2-style weight decay for regularization; typically not applied to LayerNorm/bias parameters in AdamW-style setups.
weight_decay = 0.1
# Adam/AdamW beta1 (momentum) parameter; higher retains more past gradients.
beta1 = 0.9
# Adam/AdamW beta2 (second-moment) parameter; higher smooths variance more but reacts slower to changes.
beta2 = 0.95
# Gradient norm clipping threshold to prevent exploding gradients; 0 or None would disable if supported.
grad_clip = 1.0

[train.schedule]
# Whether to apply a learning-rate schedule (typically warmup + decay).
decay_lr = true
# Number of warmup iterations from 0 -> learning_rate; ignored if decay_lr = false.
warmup_iters = 2000
# Number of iterations over which to decay from learning_rate down toward min_lr; align with max_iters for cosine/poly schedules.
lr_decay_iters = 100_000
# Lower bound (floor) for the learning rate during decay; helps avoid stalling late in training.
min_lr = 0.00003

[train.runtime]
# Output directory for logs, checkpoints, and metadata for this training run.
out_dir = "ml_playground/experiments/bundestag_char/out"
# Total number of optimizer iterations to run (across all accumulation steps).
max_iters = 100_000
# How often (in iterations) to run evaluation/checkpoint logic.
eval_interval = 1_000
# Number of evaluation batches to average per evaluation; higher reduces noise but takes longer.
eval_iters = 100
# How often (in iterations) to log training metrics.
log_interval = 20
# If true, only runs evaluation and exits (no training updates); useful for validating or benchmarking.
eval_only = false
# If true, save a checkpoint on every eval (last and/or best/top-k as configured); increases disk usage.
always_save_checkpoint = false
# Random seed for reproducibility (data shuffling, init, sampling).
seed = 1337
# Compute device backend: "cuda" (NVIDIA), "mps" (Apple Silicon), or "cpu".
device = "mps"
# Numeric precision for tensors and parameters; affects speed/memory vs. stability/accuracy.
dtype = "bfloat16"
# If true, compile/optimize the model/graph (when supported); speeds up but increases startup time.
compile = false

# checkpoint policy
# Filename for the most recent checkpoint snapshot saved (rolling "last" save).
ckpt_last_filename = "ckpt_last.pt"
# Filename pattern/name for the best-scoring checkpoint according to ckpt_metric.
ckpt_best_filename = "ckpt_best.pt"
# Keep the top-K best checkpoints (by ckpt_metric) in addition to "last"; 0 disables top-K retention.
ckpt_top_k = 3
# Metric key to select "best" (e.g., "val_loss"); must match what evaluation reports.
ckpt_metric = "val_loss"
# Whether higher metric values are better (true) or lower are better (false); e.g., false for "val_loss".
ckpt_greater_is_better = false
# Atomic write of checkpoint files to avoid partial files on crashes.
ckpt_atomic = true
# If true, write extra metadata (e.g., config, metrics) alongside checkpoints for reproducibility.
ckpt_write_metadata = true
# Minimum time between time-based checkpoint saves; 0 disables time-based saves.
# When > 0, can save on a timer in addition to eval_interval-driven saves.
ckpt_time_interval_minutes = 0
# Exponential smoothing coefficient for the metric used to decide "best"; 0.0 disables smoothing.
# Smoothing can reduce checkpoint churn and interacts with early_stop_patience.
best_smoothing_alpha = 0.9
# Early stopping patience in number of evaluations without improvement; 0 disables early stopping.
early_stop_patience = 10
# Exponential Moving Average (EMA) decay for model weights; 0.0 disables.
# If >0, evaluations/checkpoints may use EMA weights for better validation stability.
ema_decay = 0.999

[sample.runtime]
# Output directory to read checkpoints from (and optionally write samples/logs to).
# Typically should match the training run's out_dir you want to sample from.
out_dir = "ml_playground/experiments/bundestag_char/out"
# Iteration controls are usually inert for pure sampling, but kept for API symmetry.
max_iters = 0
# Evaluation cadence placeholders (often unused in pure sampling flows).
eval_interval = 1
# Number of evaluation batches during sampling flows (often unused).
eval_iters = 1
# Logging cadence during sampling (if the driver logs progress).
log_interval = 1
# If true, run evaluation-only behavior in sampling loop implementations that support it.
eval_only = false
# Whether to save artifacts during sampling (e.g., generated text dumps); false to avoid clutter.
always_save_checkpoint = false
# Seed to make generation reproducible for a fixed prompt and settings.
seed = 1337
# Device to run generation on; "cpu" is fine for small char-level models, use "cuda"/"mps" if available.
device = "mps"
# Numeric precision during sampling; can be lower precision if supported to speed up generation.
dtype = "float16"
# Whether to compile/optimize the model for inference (if supported); usually false for quick runs.
compile = false

[sample.sample]
# Prompt to prime the model; generation continues after this text.
start = "\n(Beifall bei der FDP): \n"
# Number of independent samples to generate for the same prompt/settings.
num_samples = 2
# Maximum number of new tokens to generate after the prompt.
max_new_tokens = 1024
# Softens or sharpens the probability distribution before sampling; higher = more random, 0 = greedy/argmax.
temperature = 0.8
# Sample only from the top-K most likely tokens at each step; lower K increases coherence, higher K increases diversity.
# Interplay: lower temperature + small top_k -> focused, deterministic-like; higher temperature + large top_k -> diverse/creative.
top_k = 100
